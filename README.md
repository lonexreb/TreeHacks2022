# TreeHacks2022
FoodMood : A Computer Vision app that scans food which the users intake and keep a track of their mood throughout the day 
Inspiration
Much is known about how caloric input can affect body appearance. Little, however, is talked about the effects of healthy eating habits on the production of neurotransmitters and mental health outcomes. Neurotransmitters are chemicals that help the brain communicate information across multiple neurostructures. Dietary habits play an important role in the production of neurotransmitters as they provide molecules (in the form of nutrients, for example) that favor the production of certain behaviors. In short, some neurotransmitters favor the expression of certain behaviors and mood changes, therefore, dietary habits can play a role in how humans behave and interact with the world. Our idea is based on very recent, innovative neuroscience research that is working to understand the hidden ways in which neurotransmitters contribute to humans’ wellbeing. Showing people how their dietary habits influence their behavior and mood change is beneficial because it creates a channel for change and improvement in habits. A poor diet has been scientifically linked to the development of mental and physical discomfort. Even worse, a poor diet can strengthen symptoms and increase the likelihood of the development of mental illnesses such as depression and anxiety. Our app can serve as an incentive for people to change their lifestyle for healthier habits.

How we built it
We started, FoodMood to be an android app that will predict your mood on the basis of the food that you consume. The user will take a photo of their food and upload it and on that basis, we can predict their mood. We classified data in CSV files and built the Computer Vision backend, GAN. We tried to build the CV API which to is called in the Android App which didn't work and took a substantial amount of time. So we pivoted it to be a web app. We used Bubble to make the UI and connect API via Bubble API connector.

What it does
Foodmood allows users to scan their meals on the spot and receive a quick report on how the ingestion of that food might affect their mood and behavior throughout the day. Our app also provides a quick environmental report to the user, showing how the production of that food item affected Carbon emissions. This is especially important as visualizing this type of data in a simple way can be a powerful incentive for people to change their habits. Our app uses data backed up by neuroscience research to assess food items and tell users that they might see a certain type of mood change as a result of consuming that particular meal. Eating a burger, for example, might lead to an increase in the brain’s production of dopamine receptors, which translates to a person feeling pleasure and satisfaction. Over a short period of time, however, that satisfaction turns into a sensation of lethargy and tiredness, which is characteristic of consumption of food that is high in fat and sugar. Our app will identify the burger (or whatever they are eating) and show the user how they might feel shortly as a result of that intake. Some fruits and vegetables are known for increasing attention and the ability to learn new skills. When somebody sees that information through our app, they might become naturally inclined to eating more healthy items as an outcome of having that information about food benefit fresh in their brain. With a quick picture analysis, our app shows users how their mood might change, giving insight into how better eating habits may favor a happier lifestyle.

Challenges we ran into
The first major blockage was determining what workflow we had to use for the computer vision model during the initial part of the hackathon. We were planning to have it done with a pre-trained model, but determined for the scope of the project that we would use an existing API from Clarai to achieve classification of different kinds of food. We also ran into logistical issues when it came to collaboration, such as different time zones and minor technical problems with internet connection. There was also a learning curve in customizing Bubble for ML purposes. Also we had scope creep issues, where we initially were planning to create an android app in Java, but determined halfway through there was not enough time to debug the API calls on Android Studio and went with using Bubble instead.

Accomplishments that we're proud of
We were very proud to have finished a project to present! We ran through many obstacles in this hackathon, so even finishing a final product to present is a huge accomplishment for us! The accomplishment we are the most proud of is the idea itself, which could realistically become a real-world project that helps people improve their mental health and daily moods in a very simple way.

Built With
bubble
clarifai
intersystems
